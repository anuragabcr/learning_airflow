{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21524172-605f-4474-a290-69620cf70d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e827cb89-bda1-4992-a18b-0c61a18bdb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f587d64f-96d1-40d5-a42b-0990c090ead1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_entries = []\n",
    "\n",
    "def log_event(event_type, message, table=None):\n",
    "    \"\"\"Log an event and store it in the log list\"\"\"\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"event_type\": event_type,\n",
    "        \"message\": message,\n",
    "        \"table\": table\n",
    "    }\n",
    "    log_entries.append(log_entry)\n",
    "    print(f\"[{log_entry['timestamp']}] {event_type} - {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3986b972-30fa-4929-a78c-5e71419c2dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HospitalASqlToLanding\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e763480-2a4b-4828-aa5d-f8568302c395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCP_BUCKET=\"healthcare-bucket-0201\"\n",
    "HOSPITAL_NAME=\"hospital-b\"\n",
    "LANDING_PATH=f\"gs://{GCP_BUCKET}/landing/{HOSPITAL_NAME}/\"\n",
    "ARCHIVE_PATH=f\"gs://{GCP_BUCKET}/landing/{HOSPITAL_NAME}/archive/\"\n",
    "CONFIG_FILE_PATH=f\"gs://{GCP_BUCKET}/configs/load_config.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbe52a3d-acad-4996-b1a2-64293c10f649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_PROJECT=\"learning-0201\"\n",
    "BQ_AUDIT_TABLE=f\"{BQ_PROJECT}.temp_dataset.audit_log\"\n",
    "BQ_LOG_TABLE=f\"{BQ_PROJECT}.temp_dataset.pipeline_logs\"\n",
    "BQ_TEMP_PATH=f\"{GCP_BUCKET}/temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601679f-6523-48b4-abb6-70a16979d590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MYSQL_CONFIG = {\n",
    "    \"url\": \"jdbc:mysql://10.13.176.3/hospital-a-db?useSSL=true&allowPublicKeyRetrieval=true\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"user\": \"\",\n",
    "    \"password\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "655c9e02-3d5f-4de0-894a-4bd65a76725b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-02T09:48:20.809931] INFO - Successfully read the config file\n"
     ]
    }
   ],
   "source": [
    "def read_config_file():\n",
    "    df = spark.read.csv(CONFIG_FILE_PATH, header=True)\n",
    "    log_event(\"INFO\", \"Successfully read the config file\")\n",
    "    return df\n",
    "\n",
    "config_df = read_config_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c311c28-040a-4f04-8ea2-f590239dfe22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_existing_files_to_archive(table):\n",
    "    blobs = list(storage_client.bucket(GCP_BUCKET).list_blobs(prefix=f\"landing/{HOSPITAL_NAME}/{table}/\"))\n",
    "    existing_files = [blob.name for blob in blobs if blob.name.endswith(\".json\")]\n",
    "    \n",
    "    if not existing_files:\n",
    "        log_event(\"INFO\", f\"No existing files for table {table}\")\n",
    "        return\n",
    "    \n",
    "    for file in existing_files:\n",
    "        source_blob = storage_client.bucket(GCP_BUCKET).blob(file)\n",
    "        \n",
    "        date_part = file.split(\"_\")[-1].split(\".\")[0]\n",
    "        year, month, day = date_part[-4:], date_part[2:4], date_part[:2]\n",
    "        \n",
    "        archive_path = f\"landing/{HOSPITAL_NAME}/archive/{table}/{year}/{month}/{day}/{file.split('/')[-1]}\"\n",
    "        dest_blob = storage_client.bucket(GCP_BUCKET).blob(archive_path)\n",
    "        \n",
    "        storage_client.bucket(GCP_BUCKET).copy_blob(source_blob, storage_client.bucket(GCP_BUCKET), dest_blob.name)\n",
    "        source_blob.delete()\n",
    "        \n",
    "        log_event(\"INFO\", f\"Moved {file} to {archive_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7500b1ff-6cb7-4fdb-9650-71cd4a54d21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_latest_watermark(table_name):\n",
    "    query = f\"\"\"\n",
    "        SELECT MAX(load_timestamp) AS latest_timestamp\n",
    "        FROM `{BQ_AUDIT_TABLE}`\n",
    "        WHERE tablename = '{table_name}' and data_source = \"hospital_a_db\"\n",
    "    \"\"\"\n",
    "    query_job = bq_client.query(query)\n",
    "    result = query_job.result()\n",
    "    for row in result:\n",
    "        return row.latest_timestamp if row.latest_timestamp else \"1900-01-01 00:00:00\"\n",
    "    return \"1900-01-01 00:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31911d-3abf-4dd4-96b0-a1ee78ce5a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_and_save_to_landing(table, load_type, watermark_col):\n",
    "    try:\n",
    "        last_watermark = get_latest_watermark(table) if load_type.lower() == \"incremental\" else None\n",
    "        log_event(\"INFO\", f\"Latest watermark for {table}: {last_watermark}\", table=table)\n",
    "\n",
    "        query = f\"(SELECT * FROM {table}) AS t\" if load_type.lower() == \"full\" else \\\n",
    "                f\"(SELECT * FROM {table} WHERE {watermark_col} > '{last_watermark}') AS t\"\n",
    "\n",
    "        df = (spark.read.format(\"jdbc\")\n",
    "                .option(\"url\", MYSQL_CONFIG[\"url\"])\n",
    "                .option(\"user\", MYSQL_CONFIG[\"user\"])\n",
    "                .option(\"password\", MYSQL_CONFIG[\"password\"])\n",
    "                .option(\"driver\", MYSQL_CONFIG[\"driver\"])\n",
    "                .option(\"dbtable\", query)\n",
    "                .load())\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"✅ Successfully extracted data from {table}\", table=table)\n",
    "\n",
    "        today = datetime.datetime.today().strftime('%d%m%Y')\n",
    "        JSON_FILE_PATH = f\"landing/{HOSPITAL_NAME}/{table}/{table}_{today}.json\"\n",
    "\n",
    "        bucket = storage_client.bucket(GCP_BUCKET)\n",
    "        blob = bucket.blob(JSON_FILE_PATH)\n",
    "        blob.upload_from_string(df.toPandas().to_json(orient=\"records\", lines=True), content_type=\"application/json\")\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"✅ JSON file successfully written to gs://{GCP_BUCKET}/{JSON_FILE_PATH}\", table=table)\n",
    "        \n",
    "        # Insert Audit Entry\n",
    "        audit_df = spark.createDataFrame([\n",
    "            (\"hospital_b_db\", table, load_type, df.count(), datetime.datetime.now(), \"SUCCESS\")], \n",
    "            [\"data_source\", \"tablename\", \"load_type\", \"record_count\", \"load_timestamp\", \"status\"])\n",
    "\n",
    "        (audit_df.write.format(\"bigquery\")\n",
    "            .option(\"table\", BQ_AUDIT_TABLE)\n",
    "            .option(\"temporaryGcsBucket\", GCP_BUCKET)\n",
    "            .mode(\"append\")\n",
    "            .save())\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"✅ Audit log updated for {table}\", table=table)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_event(\"ERROR\", f\"Error processing {table}: {str(e)}\", table=table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3272c16-a159-4843-b1b0-11bc66560451",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-02T10:01:49.639512] INFO - No existing files for table encounters\n",
      "[2026-01-02T10:01:50.384143] INFO - Latest watermark for encounters: 1900-01-01 00:00:00\n",
      "[2026-01-02T10:04:01.639040] ERROR - Error processing encounters: An error occurred while calling o238.load.\n",
      ": com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:840)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:416)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237)\n",
      "\tat com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)\n",
      "\tat com.mysql.cj.NativeSession.connect(NativeSession.java:142)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:964)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:828)\n",
      "\t... 29 more\n",
      "Caused by: java.net.ConnectException: Connection timed out (Connection timed out)\n",
      "\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:609)\n",
      "\tat com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)\n",
      "\t... 32 more\n",
      "\n",
      "[2026-01-02T10:04:01.679568] INFO - No existing files for table patients\n",
      "[2026-01-02T10:04:02.484444] INFO - Latest watermark for patients: 1900-01-01 00:00:00\n",
      "[2026-01-02T10:06:12.606641] ERROR - Error processing patients: An error occurred while calling o248.load.\n",
      ": com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:840)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:416)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237)\n",
      "\tat com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)\n",
      "\tat com.mysql.cj.NativeSession.connect(NativeSession.java:142)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:964)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:828)\n",
      "\t... 29 more\n",
      "Caused by: java.net.ConnectException: Connection timed out (Connection timed out)\n",
      "\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:609)\n",
      "\tat com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)\n",
      "\t... 32 more\n",
      "\n",
      "[2026-01-02T10:06:12.652444] INFO - No existing files for table transactions\n",
      "[2026-01-02T10:06:13.497255] INFO - Latest watermark for transactions: 1900-01-01 00:00:00\n",
      "[2026-01-02T10:08:23.695516] ERROR - Error processing transactions: An error occurred while calling o258.load.\n",
      ": com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:840)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:416)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237)\n",
      "\tat com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)\n",
      "\tat com.mysql.cj.NativeSession.connect(NativeSession.java:142)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:964)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:828)\n",
      "\t... 29 more\n",
      "Caused by: java.net.ConnectException: Connection timed out (Connection timed out)\n",
      "\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:609)\n",
      "\tat com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)\n",
      "\t... 32 more\n",
      "\n",
      "[2026-01-02T10:08:23.721029] INFO - No existing files for table providers\n",
      "[2026-01-02T10:08:23.721102] INFO - Latest watermark for providers: None\n",
      "[2026-01-02T10:10:34.748541] ERROR - Error processing providers: An error occurred while calling o268.load.\n",
      ": com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:840)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:416)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237)\n",
      "\tat com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)\n",
      "\tat com.mysql.cj.NativeSession.connect(NativeSession.java:142)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:964)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:828)\n",
      "\t... 29 more\n",
      "Caused by: java.net.ConnectException: Connection timed out (Connection timed out)\n",
      "\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:609)\n",
      "\tat com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)\n",
      "\t... 32 more\n",
      "\n",
      "[2026-01-02T10:10:34.802045] INFO - No existing files for table departments\n",
      "[2026-01-02T10:10:34.802102] INFO - Latest watermark for departments: None\n",
      "[2026-01-02T10:12:45.877830] ERROR - Error processing departments: An error occurred while calling o278.load.\n",
      ": com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:165)\n",
      "\tat com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:55)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:840)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.<init>(ConnectionImpl.java:416)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237)\n",
      "\tat com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:180)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:160)\n",
      "\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:156)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: com.mysql.cj.exceptions.CJCommunicationsException: Communications link failure\n",
      "\n",
      "The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:52)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:95)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createException(ExceptionFactory.java:140)\n",
      "\tat com.mysql.cj.exceptions.ExceptionFactory.createCommunicationsException(ExceptionFactory.java:156)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:79)\n",
      "\tat com.mysql.cj.NativeSession.connect(NativeSession.java:142)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:964)\n",
      "\tat com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:828)\n",
      "\t... 29 more\n",
      "Caused by: java.net.ConnectException: Connection timed out (Connection timed out)\n",
      "\tat java.base/java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)\n",
      "\tat java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.base/java.net.Socket.connect(Socket.java:609)\n",
      "\tat com.mysql.cj.protocol.StandardSocketFactory.connect(StandardSocketFactory.java:144)\n",
      "\tat com.mysql.cj.protocol.a.NativeSocketConnection.connect(NativeSocketConnection.java:53)\n",
      "\t... 32 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in config_df.collect():\n",
    "    if row[\"is_active\"] == '1' and row[\"datasource\"] == \"hospital_b_db\": \n",
    "        db, src, table, load_type, watermark, _, targetpath = row\n",
    "        move_existing_files_to_archive(table)\n",
    "        extract_and_save_to_landing(table, load_type, watermark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05c885b9-3391-49d9-9970-a44edefad87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_logs_to_gcs():\n",
    "    \"\"\"Save logs to a JSON file and upload to GCS\"\"\"\n",
    "    log_filename = f\"pipeline_log_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "    log_filepath = f\"temp/pipeline_logs/{log_filename}\"  \n",
    "    \n",
    "    json_data = json.dumps(log_entries, indent=4)\n",
    "\n",
    "    # Get GCS bucket\n",
    "    bucket = storage_client.bucket(GCP_BUCKET)\n",
    "    blob = bucket.blob(log_filepath)\n",
    "    \n",
    "    # Upload JSON data as a file\n",
    "    blob.upload_from_string(json_data, content_type=\"application/json\")\n",
    "\n",
    "    print(f\"✅ Logs successfully saved to GCS at gs://{GCP_BUCKET}/{log_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebfda6ef-0ad0-4736-8c3a-334bb6123a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_logs_to_bigquery():\n",
    "    \"\"\"Save logs to BigQuery\"\"\"\n",
    "    if log_entries:\n",
    "        log_df = spark.createDataFrame(log_entries)\n",
    "        log_df.write.format(\"bigquery\") \\\n",
    "            .option(\"table\", BQ_LOG_TABLE) \\\n",
    "            .option(\"temporaryGcsBucket\", BQ_TEMP_PATH) \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "        print(\"✅ Logs stored in BigQuery for future analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6858e220-27a6-456e-8aab-d7e1c03b2e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logs successfully saved to GCS at gs://healthcare-bucket-0201/temp/pipeline_logs/pipeline_log_20260102103028.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logs stored in BigQuery for future analysis\n"
     ]
    }
   ],
   "source": [
    "save_logs_to_gcs()\n",
    "save_logs_to_bigquery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed7c1e-1201-4a92-8843-e19e35fcd5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
